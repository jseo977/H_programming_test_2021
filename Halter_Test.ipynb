{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Halter_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IMh5vLQKQyVJ",
        "hL_gvNlnaAw6",
        "WauXvORDRfxe"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFI0FG12RIvW"
      },
      "source": [
        "# Halter Technical Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMcUJpddRkfr"
      },
      "source": [
        "This is the Google Colab notebook containing the code to complete the Halter Technical Test. Please refer to the README.md provided in the email for instructions and answers to the questions.\n",
        "\n",
        "You may wish to use 'Runetime > Run all' if you do not wish to sequentially run the code cells. It is also recommended that you make use of the Google Colab GPUs as it will significantly improve the code compilation time.\n",
        "\n",
        "The README.md text is also appended at the end of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vype_7uRLCP"
      },
      "source": [
        "# Imports and Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7NRE5wzgdY-"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "\n",
        "# Initialise\n",
        "IMG_SIZE = 28\n",
        "\n",
        "# Load dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(images_train, labels_train), (images_test, labels_test) = mnist.load_data()\n",
        "\n",
        "# Normalise and reshape dataset preprocessing and input to Convolutional Neural Network\n",
        "images_train = tf.keras.utils.normalize(images_train, axis=1)\n",
        "images_test = tf.keras.utils.normalize(images_test, axis=1)\n",
        "images_train = images_train.reshape(len(images_train), IMG_SIZE, IMG_SIZE, 1)\n",
        "images_test = images_test.reshape(len(images_test), IMG_SIZE, IMG_SIZE, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CBxACjdDPJt"
      },
      "source": [
        "# Preprocessing\n",
        "Perform data augmentation on training dataset to minimise bias and potential for overfitting when fitting the sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mmc-HK2r_Xt"
      },
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=25,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2)\n",
        "\n",
        "# Create Iterator objects to pass into model.fit_generator()\n",
        "train_generator = datagen.flow(images_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMh5vLQKQyVJ"
      },
      "source": [
        "# Model Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7lJBNMNZREo"
      },
      "source": [
        "This is a remnant of some code that I used to optimise my Machine Learning Model.\n",
        "I don't recommend that you run this code, as I have already shown and chosen my final model below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcxbt2BAZPdi"
      },
      "source": [
        "# Set this to false by default as you will probably not want to train and test over 100\n",
        "# Convolutional Neural Networks\n",
        "run_hyper_param_opt = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL_gvNlnaAw6"
      },
      "source": [
        "## Hyperparameter Optimisation\n",
        "I have performed a coarse Hyperparameter Optimisation below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hBPLLj7gFx1"
      },
      "source": [
        "# Iteratively create a new model\n",
        "opt = ['agd', 'rmsprop', 'adam']\n",
        "loss = ['categorical_crossentropy', 'poisson']\n",
        "conv_layers = [1, 2, 3]\n",
        "dense_layers = [1, 2, 3 , 4, 5]\n",
        "layer_sizes = [32, 64, 128, 256]\n",
        "dropout = [0, 0.2, 0.4, 0.8]\n",
        "epochs = [10, 12, 15, 18, 20]\n",
        "\n",
        "# Hyperparameter Optimisation\n",
        "if run_hyper_param_opt:\n",
        "  for dense_layer in dense_layers:\n",
        "      for layer_size in layer_sizes:\n",
        "          for drop in dropout:\n",
        "              for epoch in epochs:\n",
        "                # Initialise naming and callback for Tensorboard analysis later\n",
        "                name = \"Test_Epoch_Single_No_Dropout_{}_nodes_{}_dense_{}_time\".format(drop, layer_size, dense_layer, int(time.time()))\n",
        "                tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
        "                print(name)\n",
        "\n",
        "                model = Sequential()\n",
        "                # Convolutional/Input Layer \n",
        "                model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\n",
        "                model.add(MaxPool2D(pool_size=(1,1)))\n",
        "                # flatten output of conv (input) layer \n",
        "                model.add(Flatten())\n",
        "\n",
        "                # Variable number of Dense Layers\n",
        "                for i in range(dense_layer):\n",
        "                    model.add(Dense(layer_size, activation='relu'))  \n",
        "                    model.add(Dropout(drop))\n",
        "\n",
        "                # Final dense and output layer\n",
        "                model.add(Dense(layer_size, activation='relu'))\n",
        "                model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "                # compiling the sequential model\n",
        "                model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "                model.fit(images_train, labels_train, epochs=epoch, batch_size=20, validation_data=(images_test,labels_test), callbacks = [tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WauXvORDRfxe"
      },
      "source": [
        "## Analysing results with TensorBoard\n",
        "Ensure that the `'log'` folder has been uploaded into the files workspace on the left in order to view the TensorBoard with the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2sVFOZlkxDe"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXlUsP2smCT"
      },
      "source": [
        "# The Selected Model\n",
        "The below model is the selected model with the optimal parameters from the Hyperparameter optimisation. Optimisation was done in conjunction with Tensorboard analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TSFnHJ7sk3A"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(Conv2D(25,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 padding='valid',\n",
        "                 activation='relu',input_shape=(IMG_SIZE,IMG_SIZE,1))\n",
        "                 )\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=(len(images_train))//32,\n",
        "                    epochs=10\n",
        "                    )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzRND_lC-q5"
      },
      "source": [
        "## Finding the most ambiguous images\n",
        "Create a list of the images with the lowest prediction confidence percentages. These will be the images that the model finds the most 'ambiguous'. The prediction, position, and the confidence in the prediction for the top 10 images will be stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tMYFT8x1z3M"
      },
      "source": [
        "# Make model predictions for each category for each image in the testing dataset\n",
        "predictions = model.predict(images_test)\n",
        "\n",
        "# Generate a list of the 10 images with the lowest confidence predictions\n",
        "num = 10\n",
        "lowest_confidence = np.ones(num)\n",
        "lowest_conf_pos = np.zeros(num)\n",
        "lowest_conf_predict = np.zeros(num)\n",
        "counter = 0\n",
        "\n",
        "# Begin iterating through the testing dataset\n",
        "for prediction in predictions:\n",
        "    if np.max(prediction) < np.min(lowest_confidence):\n",
        "        max_pos = lowest_confidence.argmax()\n",
        "        lowest_conf_pos[max_pos] = int(counter)\n",
        "        lowest_confidence[max_pos] = np.max(prediction)\n",
        "        lowest_conf_predict[max_pos] = np.argmax(prediction)\n",
        "    counter += 1\n",
        "lowest_conf_pos = [int(i) for i in lowest_conf_pos]\n",
        "lowest_conf_predict = [int(i) for i in [int(i) for i in lowest_conf_predict]]\n",
        "\n",
        "print('lowest_confidence:')\n",
        "print(lowest_confidence)\n",
        "print('lowest_conf_pos')\n",
        "print(lowest_conf_pos)\n",
        "print('lowest_conf_predict')\n",
        "print(lowest_conf_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O2eW3hI_sJF"
      },
      "source": [
        "## Output Images\n",
        "Run the code below to save and store the output images, and have a preview of the images.\n",
        "\n",
        "Note that due to the stochastic nature of the convolutional neural network, the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbbgrNJ7Za1_"
      },
      "source": [
        "# Create subdirectory to store output files\n",
        "if not os.path.exists('outputs'):\n",
        "    os.makedirs('outputs')\n",
        "\n",
        "# Save each image into the subdirectory\n",
        "fig = plt.figure()\n",
        "for i in range(num):\n",
        "    # Subplot 10 most ambiguous images\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title('Pred: %.0f' % lowest_conf_predict[i])\n",
        "    ax.imshow(images_test[lowest_conf_pos[i]].reshape(IMG_SIZE, IMG_SIZE))\n",
        "    name = \"outputs/Low_confidence_%s_(%.5s%%).png\" % (int(lowest_conf_predict[i]), lowest_confidence[i]*100)\n",
        "    img = Image.fromarray(np.uint8(images_test[int(lowest_conf_pos[i])].reshape(IMG_SIZE, IMG_SIZE) * 255) , 'L')\n",
        "    img.save(name)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp2RVYZNgYOt"
      },
      "source": [
        "## Thank you for looking through my technical test submission!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8B3QhJRAPT9"
      },
      "source": [
        "# Halter Tech Challenge - Jae Min Seo (README.md)\n",
        "\n",
        "## Instructions\n",
        "The Google Colab linked (https://colab.research.google.com/drive/1SNWyp18lqTr6qTgBSI6U427-aKwSnkwc?usp=sharing) will have instructions on how to run the model above each code cell. As the code is compiled and run remotely on Colab, all dependencies will already be in place. How convenient!\n",
        "\n",
        "## Question One\n",
        "### Describe the model you have created. Explain the design decisions you have made in constructing the model.\n",
        "\n",
        "As the MNIST dataset is well known for being relatively simple, I did not try to create a model that was too complex. I did a fairly coarse hyperparameter optimisation on the CNN to optimise the validation accuracy and minimise the loss function for the final epoch test of each configuration. I analysed the steady-state accuracies and losses on Tensorboard, and incremented the parameters in the direction that minimised losses (eg. If a 5% dropout rate had a lower loss than 0%, I then test 10%). Parameters such as the optimizer, activation, dropout rate, number of dense layers, and number of nodes per layer were perturbed in the optimisation. \n",
        "\n",
        "Ultimately, I landed at a basic convolutional neural network with three dense layers, and a 20% dropout rate between them. This helps to prevent any significant overfitting and minimise bias. Whilst the MNIST dataset is relatively noise-free, it was still important to have a robust dataset when finding the images in the test dataset that deviates the most from the training dataset. To further prevent overfitting and improve the overall robustness of the model, I did data augmentation on the training data, though not a significant amount as there is already a large amount of quality data in the training dataset.\n",
        "\n",
        "After the model was created, each image in the test dataset was iterated through, and their images with the lowest confidence in their predictions from the model were collated, and saved in a subdirectory.\n",
        "\n",
        "## Question Two\n",
        "### Analyse your results: do the 10 images you have found align with your expectations? Why do you think this is? State how you have quantified “most ambiguous”.\n",
        "\n",
        "Due to the stochastic nature of CNN compilation and fitting, I did not get consistent ambiguous outputs from the MNIST test dataset. However, there were clearly some images that repeated in each test more than others.\n",
        "\n",
        "I quantified ‘ambiguity’ as how low the machine learning model’s prediction is when classifying an image. I found that this was a fairly good measure of how hard to classify an image, as even after a brief visual look through the outputted files, I could understand how a machine could misinterpret the result. However, my model did attempt to classify the ambiguous results, and I found that the model did appear to be correct around half of the time.\n",
        "\n",
        "Common trends between images that had a low prediction scores were images where the stroke voxel appeared to touch the edge of the image, or where the stroke was lifted and continued on another part of the image. Other cases included where angled/circular strokes were too small relative to the straight strokes and created a somewhat distorted image. A reason for the misclassifications  could be class noise: After a rough visual inspection of images in the MNIST dataset, I definitely saw images that could have been a contradictory instance of one of two numbers. However, there were definitely some images that were clearly misclassified, and this is more due to my own model than the data.\n",
        "\n",
        "\n",
        "## Question Three\n",
        "### Lets say your only goal is to train the best handwritten digit classifier on earth, using this dataset. What do you think the impact is of these ‘hard to classify’ images on the performance? How could you use your ‘hard to classify’ image detector to improve this?\n",
        "\n",
        "Noisy data is known to cause needless convolutions and complexity to a machine learning model, whilst also increasing the time of learning. This ultimately leads to the degradation of performance of machine learning algorithms. A result of this could be decrease validation/classification accuracy, as well as poor predictions.\n",
        "\n",
        "This ‘hard to classify’ image detector could be used to systematically remove data that was noisy or cause adverse effects to the machine learning model. This means that the training dataset -when fitting a machine learning model- can be compiled and fitted faster (eg. remove excess connections between dense layers - minimise needs for dropouts), increase model accuracy, and overall improve the complexity and time to complete the model.\n",
        "A limitation is that my model it itself has already been trained with some ambiguous images from the raw MNIST dataset. This can cause potential biasing issues. This bias could be seen in certain occasions in my model, as some of the classifications had relatively high confidence predictions for some images that visually appeared quite ambiguous. An initial supervised model would be recommended in such an instance, or a model trained from a relatively more noise-free dataset."
      ]
    }
  ]
}